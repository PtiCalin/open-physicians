{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Physicians Dataset Workbook\n",
    "\n",
    "This workbook provides a lightweight walkthrough for loading, inspecting, and summarizing the curated physicians dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def resolve_data_path(filename: str) -> Path:\n",
    "    cwd = Path.cwd()\n",
    "    candidates = [cwd / \"data\" / \"cleaned\" / filename]\n",
    "    candidates += [parent / \"data\" / \"cleaned\" / filename for parent in cwd.parents]\n",
    "\n",
    "    for candidate in candidates:\n",
    "        if candidate.exists():\n",
    "            return candidate\n",
    "\n",
    "    kaggle_root = Path(\"/kaggle/input\")\n",
    "    kaggle_searched = False\n",
    "    if kaggle_root.exists():\n",
    "        matches = list(kaggle_root.rglob(filename))\n",
    "        kaggle_searched = True\n",
    "        if matches:\n",
    "            return matches[0]\n",
    "\n",
    "    searched = [str(path) for path in candidates]\n",
    "    if kaggle_searched:\n",
    "        searched.append(f\"{kaggle_root} (recursively via rglob)\")\n",
    "    raise FileNotFoundError(\n",
    "        \"Could not find the dataset file. Searched: \" + \", \".join(searched)\n",
    "    )\n",
    "\n",
    "\n",
    "DATA_PATH = resolve_data_path(\"physicians_clean.csv\")\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snapshot\n",
    "\n",
    "Use the cells below to understand the dataset footprint before diving deeper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coverage checks\n",
    "\n",
    "These checks highlight missing values and coverage for key fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_rate = df.isna().mean().sort_values(ascending=False)\n",
    "missing_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df.empty:\n",
    "    print(\"The dataset is currently empty. Run the ingestion pipeline to populate it.\")\n",
    "else:\n",
    "    display(df['license_status'].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "- Filter by `location_code` or `specialty_code` for targeted profiling.\n",
    "- Join against mapping tables in `mappings/` for human-readable labels.\n",
    "- Export subsets for downstream modeling or QA workflows."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}